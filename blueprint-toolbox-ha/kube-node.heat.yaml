heat_template_version: 2013-05-23

parameters:
  token:
    label: token
    type: string
  peer:
    label: peer
    type: string
  floating_network:
    label: floating_network
    type: string
  mastercount:
    label: mastercount
    type: number
  nodecount:
    label: nodecount
    type: number
  subnet:
    label: subnet
    type: string
  os_username:
    label: os_username
    type: string
  os_password:
    label: os_password
    type: string
  os_tenant:
    label: os_tenant
    type: string
  os_tenant_id:
    label: os_tenant_id
    type: string
  os_auth:
    label: os_auth
    type: string
  os_region:
    label: os_region
    type: string
  network:
    label: network
    type: string
  security_group:
    label: security_group
    type: string
  keypair_name:
    description: Keypair to inject in instance
    label: SSH Keypair
    type: string
  domain:
    description: Wildcarded domain, ex example.com must have a *.example.com DNS entry
    label: Cloud DNS
    type: string
  flavor_name:
    label: Instance Type (Flavor)
    description: Flavor to use for the deployed instance
    type: string
  vpn_username:
    label: vpn_username
    type: string
  vpn_password:
    label: vpn_password
    type: string

resources:
  port:
    type: OS::Neutron::Port
    properties:
      network: { get_param: network }
      security_groups:
        - { get_param: security_group }

  node:
    type: OS::Nova::Server
    properties:
      key_name: { get_param: keypair_name }
      image: CoreOS Stable 1010.6
      flavor: { get_param: flavor_name }
      user_data_format: RAW
      networks:
        - port: { get_resource: port }
      user_data:
        str_replace:
          params:
            $private_ipv4$: { get_attr: [ port, fixed_ips, 0, ip_address ] }
            $public_ipv4$: { get_attr: [ floating_ip, floating_ip_address] }
            $domain$: { get_param: domain }
            $os_username$: { get_param: os_username}
            $os_password$: { get_param: os_password}
            $os_tenant$: { get_param: os_tenant }
            $os_auth$: { get_param: os_auth }
            $os_region$: { get_param: os_region }
            $os_project_id$: { get_param: 'OS::project_id' }
            $node_count$: { get_param: nodecount }
            $master_count$: { get_param: mastercount }
            $subnet$: { get_param: subnet }
            $token$: { get_param: token }
            $peer$: { get_param: peer }
            $vpn_username: { get_param: vpn_username }
            $vpn_password: { get_param: vpn_password }
          template: |
            #cloud-config
            write_files:
              - path: /opt/weave-init.sh
                permissions: 0700
                owner: "root:root"
                content: |
                  #!/bin/bash
                  echo WEAVE_PEERS=\"$peer$\" > /etc/weave.env
                  echo WEAVEPROXY_ARGS=\"--rewrite-inspect\" >> /etc/weave.env
              - path: /opt/pidalio-init.sh
                permissions: 0700
                owner: "root:root"
                content: |
                  #!/bin/bash
                  NODE_NAME=$(hostname |cut -d '.' -f 1)
                  NODE_FQDN=$(hostname)
                  NODE_ID=$(curl -s http://169.254.169.254/openstack/latest/meta_data.json | jq -r .uuid)
                  cat <<EOF > /etc/pidalio.env
                  NODE_NAME=$NODE_NAME
                  NODE_FQDN=$NODE_FQDN
                  NODE_ID=$NODE_ID
                  NODE_IP=$private_ipv4$
                  NODE_PUBLIC_IP=$public_ipv4$
                  PEER=$peer$
                  PIDALIO_TOKEN=$token$
                  DOMAIN=$domain$
                  OS_AUTH_URL=$os_auth$
                  OS_PASSWORD=$os_password$
                  OS_USERNAME=$os_username$
                  OS_TENANT_NAME=$os_tenant$
                  OS_PROJECT_ID=$os_project_id$
                  OS_REGION=$os_region$
                  OS_SUBNET=$subnet$
                  EOF

                  if [[ -d /opt/pidalio ]]
                  then
                    echo "Pidalio already checkout"
                  else
                    git clone https://github.com/cedbossneo/pidalio.git /opt/pidalio
                  fi
                  /opt/pidalio/init.sh
              - path: /opt/pidalio-units.sh
                permissions: 0700
                owner: "root:root"
                content: |
                  #!/bin/bash
                  set -xe
                  /usr/bin/fleetctl start /opt/pidalio.service
                  for i in $(seq 1 $master_count$)
                  do
                    /usr/bin/fleetctl start /opt/pidalio-master@$os_region$-$i.service
                  done
                  while true
                  do
                    nb_machines=$(fleetctl list-machines | grep region=$os_region$ | wc -l)
                    for i in $(seq 1 $(expr $nb_machines - $master_count$))
                    do
                      /usr/bin/fleetctl start /opt/pidalio-node@$os_region$-$i.service
                    done
                    sleep 60
                  done
              - path: /opt/pidalio.service
                permissions: 0700
                owner: "root:root"
                content: |
                  [Unit]
                  Description=Pidalio Service
                  After=weave-network.target
                  After=etcd2.service
                  Requires=weave-network.target
                  Requires=etcd2.service
                  [Service]
                  Restart=always
                  RestartSec=10
                  Environment=DOCKER_HOST=unix:///var/run/weave/weave.sock
                  ExecStartPre=/usr/bin/docker pull cedbossneo/pidalio
                  ExecStartPre=/usr/bin/etcdctl cluster-health
                  ExecStart=/usr/bin/docker run --name=pidalio \
                    -e TOKEN=$token$ \
                    -e ETCD_URI=http://$private_ipv4$:2379 \
                    cedbossneo/pidalio
                  ExecStop=/usr/bin/docker rm -f pidalio
              - path: /opt/pidalio-master@.service
                permissions: 0700
                owner: "root:root"
                content: |
                  [Unit]
                  Description=Pidalio Master Service
                  After=weave-network.target etcd2.service
                  Requires=weave-network.target etcd2.service
                  [Service]
                  Restart=always
                  RestartSec=10
                  EnvironmentFile=/etc/pidalio.env
                  Environment=MASTER=true
                  ExecStart=/opt/pidalio/start.sh
                  ExecStop=/opt/pidalio/stop.sh
                  [X-Fleet]
                  MachineMetadata=region=$os_region$
                  Conflicts=pidalio-master@*.service
                  Conflicts=pidalio-node@*.service
              - path: /opt/pidalio-node@.service
                permissions: 0700
                owner: "root:root"
                content: |
                  [Unit]
                  Description=Pidalio Node Service
                  After=weave-network.target etcd2.service
                  Requires=weave-network.target etcd2.service
                  [Service]
                  Restart=always
                  RestartSec=10
                  EnvironmentFile=/etc/pidalio.env
                  Environment=MASTER=false
                  ExecStart=/opt/pidalio/start.sh
                  ExecStop=/opt/pidalio/stop.sh
                  [X-Fleet]
                  MachineMetadata=region=$os_region$
                  Conflicts=pidalio-master@*.service
                  Conflicts=pidalio-node@*.service
              - path: /etc/kubernetes/descriptors/2-rabbitmq.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  kind: List
                  items:
                    - apiVersion: v1
                      kind: Service
                      metadata:
                        labels:
                          component: rabbitmq
                        name: rabbitmq
                      spec:
                        sessionAffinity: ClientIP
                        ports:
                          - port: 5672
                            name: main
                          - port: 15672
                            name: management
                        selector:
                          component: rabbitmq
                    - apiVersion: v1
                      kind: ReplicationController
                      metadata:
                        labels:
                          component: rabbitmq
                        name: rabbitmq-controller
                      spec:
                        replicas: 1
                        template:
                          metadata:
                            labels:
                              component: rabbitmq
                          spec:
                            containers:
                              - image: rabbitmq:management
                                name: rabbitmq
                                ports:
                                  - containerPort: 5672
                                  - containerPort: 15672
                                resources:
                                  limits:
                                    cpu: 100m
              - path: /etc/kubernetes/descriptors/3-rethinkdb.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  kind: List
                  items:
                    - apiVersion: v1
                      kind: Service
                      metadata:
                        labels:
                          db: rethinkdb
                        name: rethinkdb-driver
                      spec:
                        sessionAffinity: ClientIP
                        ports:
                          - port: 28015
                            targetPort: 28015
                            name: driver
                          - port: 80
                            targetPort: 8080
                            name: web
                        selector:
                          db: rethinkdb
                    - apiVersion: v1
                      kind: PersistentVolumeClaim
                      metadata:
                        name: toolbox-db
                        annotations:
                          volume.alpha.kubernetes.io/storage-class: anything
                      spec:
                        accessModes:
                          - ReadWriteOnce
                        resources:
                          requests:
                            storage: 10Gi
                    - apiVersion: v1
                      kind: ReplicationController
                      metadata:
                        labels:
                          db: rethinkdb
                        name: rethinkdb-rc
                      spec:
                        replicas: 1
                        selector:
                          db: rethinkdb
                          role: replicas
                        template:
                          metadata:
                            labels:
                              db: rethinkdb
                              role: replicas
                          spec:
                            containers:
                              - image: rethinkdb
                                name: rethinkdb
                                command:
                                  - rethinkdb
                                  - --bind
                                  - all
                                  - -n
                                  - rethinkdb
                                ports:
                                  - containerPort: 8080
                                    name: admin-port
                                  - containerPort: 28015
                                    name: driver-port
                                  - containerPort: 29015
                                    name: cluster-port
                                volumeMounts:
                                  - mountPath: /data
                                    name: rethinkdb-storage
                            volumes:
                              - name: rethinkdb-storage
                                persistentVolumeClaim:
                                  claimName: toolbox-db
              - path: /etc/kubernetes/descriptors/4-toolbox.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  kind: List
                  items:
                    - apiVersion: v1
                      kind: Service
                      metadata:
                        labels:
                          component: toolbox-frontend
                        name: manager
                      spec:
                        ports:
                          - port: 80
                            targetPort: 80
                        selector:
                          component: toolbox-frontend
                    - apiVersion: v1
                      kind: Service
                      metadata:
                        labels:
                          component: toolbox-backend
                        name: toolbox-backend
                      spec:
                        ports:
                          - port: 8181
                            targetPort: 8181
                        selector:
                          component: toolbox-backend
                    - apiVersion: extensions/v1beta1
                      kind: Deployment
                      metadata:
                        labels:
                          component: toolbox-frontend
                        name: toolbox-frontend
                      spec:
                        replicas: 1
                        template:
                          metadata:
                            labels:
                              component: toolbox-frontend
                          spec:
                            containers:
                              - image: cloudwattfr/toolbox-client:2.2
                                imagePullPolicy: Always
                                name: toolbox-frontend
                                ports:
                                  - containerPort: 80
                    - apiVersion: extensions/v1beta1
                      kind: Ingress
                      metadata:
                        name: toolbox
                      spec:
                        rules:
                        - http:
                            paths:
                            - path: /api
                              backend:
                                serviceName: toolbox-backend
                                servicePort: 8181
                            - path: /socket.io
                              backend:
                                serviceName: toolbox-backend
                                servicePort: 8181
                            - path: /
                              backend:
                                serviceName: manager
                                servicePort: 80
                    - apiVersion: v1
                      kind: ReplicationController
                      metadata:
                        name: traefik-ingress-controller
                        labels:
                          k8s-app: traefik-ingress-lb
                      spec:
                        replicas: 1
                        selector:
                          k8s-app: traefik-ingress-lb
                        template:
                          metadata:
                            labels:
                              k8s-app: traefik-ingress-lb
                              name: traefik-ingress-lb
                          spec:
                            terminationGracePeriodSeconds: 60
                            containers:
                            - image: traefik
                              name: traefik-ingress-lb
                              imagePullPolicy: Always
                              ports:
                              - containerPort: 80
                              - containerPort: 443
                              - containerPort: 8080
                              args:
                              - --web
                              - --kubernetes
                              - --logLevel=DEBUG
                              - --entrypoints='Name:http Address::80'
                              - --defaultentrypoints=http
                    - apiVersion: v1
                      kind: Service
                      metadata:
                        labels:
                          k8s-app: traefik-ingress-lb
                        name: traefik
                      spec:
                        sessionAffinity: ClientIP
                        type: NodePort
                        ports:
                          - port: 80
                            nodePort: 30000
                            targetPort: 80
                            name: http
                        selector:
                          k8s-app: traefik-ingress-lb
                    - apiVersion: extensions/v1beta1
                      kind: Deployment
                      metadata:
                        labels:
                          component: toolbox-backend
                        name: toolbox-backend
                      spec:
                        replicas: 1
                        template:
                          metadata:
                            labels:
                              component: toolbox-backend
                          spec:
                            containers:
                              - image: cloudwattfr/toolbox-server:2.2
                                imagePullPolicy: Always
                                command:
                                  - node
                                  - --harmony
                                  - server.bundle.js
                                  - $private_ipv4
                                  - $public_ipv4
                                name: toolbox
                                env:
                                  - name: DOMAIN
                                    value: "$domain"
                                  - name: OS_AUTH_URL
                                    value: "$os_auth"
                                  - name: STACK
                                    value: "$stack"
                                  - name: OS_TENANT_NAME
                                    value: "$os_tenant"
                                  - name: OS_REGION
                                    value: $os_region
                                  - name: OS_USERNAME
                                    valueFrom:
                                      secretKeyRef:
                                        name: openstack
                                        key: username
                                  - name: OS_PASSWORD
                                    valueFrom:
                                      secretKeyRef:
                                        name: openstack
                                        key: password
                                  - name: REPLICAS
                                    value: "1"
                                ports:
                                  - containerPort: 8181
                                volumeMounts:
                                  - mountPath: /keys
                                    name: key-storage
                            volumes:
                              - name: key-storage
                                hostPath:
                                  path: /home/core/keys
              - path: /etc/environment
                permissions: 0666
                owner: "root:root"
                content: |
                  COREOS_PRIVATE_IPV4=$private_ipv4
                  COREOS_PUBLIC_IPV4=$public_ipv4
                  ETCD_ADDR=$private_ipv4:2379
                  ETCD_PEER_ADDR=$private_ipv4:2380
                  TOOLBOX_DOMAIN=$domain
            coreos:
              fleet:
                  public-ip: "$public_ipv4$"
                  metadata: "region=$os_region$"
              units:
                - name: etcd2.service
                  command: start
                  content: |
                    [Unit]
                    Description=etcd2
                    After=weave-network.target
                    Requires=weave-network.target
                    Conflicts=etcd.service

                    [Service]
                    EnvironmentFile=-/etc/weave.env
                    ExecStartPre=/opt/bin/weave expose
                    ExecStart=/opt/pidalio-init.sh
                    ExecStop=/usr/bin/docker rm -f etcd etcd-proxy
                    Restart=always
                    RestartSec=10s
                    LimitNOFILE=40000
                    TimeoutStartSec=5m

                    [Install]
                    WantedBy=multi-user.target
                - name: fleet.service
                  command: start
                - name: weave-network.target
                  enable: true
                  content: |
                    [Unit]
                    Description=Weave Network Setup Complete
                    Documentation=man:systemd.special(7)
                    RefuseManualStart=no
                    [Install]
                    WantedBy=multi-user.target
                - name: weave-init.service
                  command: start
                  content: |
                    [Unit]
                    Before=install-weave.service
                    Description=Install Weave
                    [Service]
                    Type=oneshot
                    RemainAfterExit=yes
                    TimeoutStartSec=5m
                    ExecStart=/opt/weave-init.sh
                - name: 10-weave.network
                  runtime: false
                  content: |
                    [Match]
                    Type=bridge
                    Name=weave*
                    [Network]
                - name: install-weave.service
                  enable: true
                  content: |
                    [Unit]
                    After=docker.service weave-init.service
                    Requires=docker.service weave-init.service
                    Before=weave.service
                    Description=Install Weave
                    Requires=network-online.target
                    [Service]
                    EnvironmentFile=-/etc/weave.env
                    Type=oneshot
                    RemainAfterExit=yes
                    TimeoutStartSec=5m
                    ExecStartPre=/bin/mkdir -p /opt/bin/
                    ExecStartPre=/usr/bin/curl \
                      --silent \
                      --location \
                      git.io/weave \
                      --output /opt/bin/weave
                    ExecStartPre=/usr/bin/chmod +x /opt/bin/weave
                    ExecStart=/opt/bin/weave setup
                    [Install]
                    WantedBy=weave-network.target
                    WantedBy=weave.service
                - name: weaveproxy.service
                  enable: true
                  content: |
                    [Unit]
                    After=install-weave.service
                    After=docker.service
                    Description=Weave proxy for Docker API
                    Requires=docker.service
                    Requires=install-weave.service
                    [Service]
                    EnvironmentFile=-/etc/weave.env
                    ExecStartPre=/opt/bin/weave launch-proxy $WEAVEPROXY_ARGS
                    ExecStart=/usr/bin/docker attach weaveproxy
                    Restart=on-failure
                    ExecStop=/opt/bin/weave stop-proxy
                    [Install]
                    WantedBy=weave-network.target
                - name: weave.service
                  enable: true
                  content: |
                    [Unit]
                    After=install-weave.service
                    After=docker.service
                    Description=Weave Network Router
                    Documentation=http://weave.works/docs
                    Requires=docker.service
                    Requires=install-weave.service
                    [Service]
                    TimeoutStartSec=5m
                    EnvironmentFile=-/etc/weave.env
                    ExecStartPre=/opt/bin/weave launch-router $WEAVE_PEERS
                    ExecStart=/usr/bin/docker attach weave
                    Restart=on-failure
                    ExecStop=/opt/bin/weave stop-router
                    [Install]
                    WantedBy=weave-network.target
                - name: pidalio-launch.service
                  command: start
                  content: |
                    [Unit]
                    After=fleet.service etcd2.service
                    Requires=fleet.service etcd2.service
                    [Service]
                    Restart=always
                    RestartSec=10
                    TimeoutStartSec=5m
                    ExecStart=/opt/pidalio-units.sh
                - name: pptp.service
                  command: start
                  content: |
                    [Unit]
                    Description=PPTP
                    After=docker.service
                    Requires=docker.service
                    [Service]
                    TimeoutStartSec=0
                    Restart=always
                    RestartSec=10
                    ExecStartPre=-/usr/bin/docker kill pptp
                    ExecStartPre=-/usr/bin/docker rm pptp
                    ExecStartPre=/usr/bin/docker pull cedbossneo/pptp
                    ExecStart=/bin/bash -c "\
                      docker run \
                        --name pptp \
                        --privileged \
                        --net=host \
                        --env 'USERNAME=$vpn_username' \
                        --env 'PASSWORD=$vpn_password' \
                        cedbossneo/pptp \
                    "
                    ExecStop=/usr/bin/docker stop pptp

  floating_ip_link:
    type: OS::Nova::FloatingIPAssociation
    properties:
      floating_ip: { get_resource: floating_ip }
      server_id: { get_resource: node }

  floating_ip:
    type: OS::Neutron::FloatingIP
    properties:
      floating_network_id: { get_param: floating_network }

outputs:
  public_ip:
    value: {get_attr: [floating_ip, floating_ip_address]}
